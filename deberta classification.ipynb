{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9abdc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\yehoshd\\appdata\\roaming\\python\\python311\\site-packages (4.38.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\yehoshd\\appdata\\roaming\\python\\python311\\site-packages (2.18.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\yehoshd\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\yehoshd\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yehoshd\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\yehoshd\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\yehoshd\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yehoshd\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\yehoshd\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\yehoshd\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "   ---------------------------------------- 0.0/84.1 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 41.0/84.1 kB ? eta -:--:--\n",
      "   -------------------------------------- - 81.9/84.1 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 84.1/84.1 kB 677.9 kB/s eta 0:00:00\n",
      "Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.1 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 112.6/290.1 kB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 225.3/290.1 kB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 256.0/290.1 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  286.7/290.1 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 290.1/290.1 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: responses, accelerate, evaluate\n",
      "Successfully installed accelerate-0.28.0 evaluate-0.4.1 responses-0.18.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts accelerate-config.exe, accelerate-estimate-memory.exe, accelerate-launch.exe and accelerate.exe are installed in 'C:\\Users\\YEHOSHD\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script evaluate-cli.exe is installed in 'C:\\Users\\YEHOSHD\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05185f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: protobuf==3.20.* in c:\\programdata\\anaconda3\\lib\\site-packages (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789e054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f03e5ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15db88997330489581457a673af3f4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ac1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file=r\"./data/all_data_us_IsraelSentimentTweet__updated_to_2024-02-20__16_33.xlsx\"\n",
    "full_tweets_df = pd.read_excel(df_file)\n",
    "full_tweets_df['upload_date'] = pd.to_datetime(full_tweets_df['upload_date'])\n",
    "new_twits = full_tweets_df[full_tweets_df['upload_date'] >= '2023-11-15']\n",
    "tweets_df_unprocessed = new_twits[[\"post_text\", \"conflict_sentiment\"]]\n",
    "tweets_df_unprocessed.columns = [\"text\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10a4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN\n",
    "tweets_df = tweets_df_unprocessed.copy(deep=True)\n",
    "tweets_df.dropna(inplace=True)\n",
    "# Convert conflict_sentiment to numeric\n",
    "tweets_df['label'] = pd.to_numeric(tweets_df['label'], errors='coerce')\n",
    "# Convert conflict_sentiment values which are different than 0 to 1\n",
    "tweets_df['label'] = tweets_df['label'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c6431-66ba-4feb-852a-69a74c369e0e",
   "metadata": {},
   "source": [
    "### Automatic train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5abada1-710f-4ac7-99fe-df1edf742505",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frac = 0.2\n",
    "\n",
    "tweets_df_0 = tweets_df[tweets_df[\"label\"] == 0]\n",
    "tweets_df_1 = tweets_df[tweets_df[\"label\"] == 1]\n",
    "\n",
    "len_label_0 = len(tweets_df_0)\n",
    "len_label_1 = len(tweets_df_1)\n",
    "\n",
    "test_1 = int(test_frac*len_label_1)\n",
    "train_1 = len_label_1 - test_1\n",
    "if len_label_0 >= 4*len_label_1:\n",
    "    train_0 = 4*train_1\n",
    "    test_0 = 4*test_1\n",
    "else:\n",
    "    test_0 = int(test_frac*len_label_0)\n",
    "    train_0 = len_label_0 - test_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5485fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77162, 4985)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_0 = 12000\n",
    "# test_0 = 8000\n",
    "# train_1 = 3000\n",
    "# test_1 = 1985\n",
    "\n",
    "seed_value = 42\n",
    "\n",
    "train_df_0 = tweets_df_0[:-test_0]\n",
    "train_df_0 = train_df_0.sample(n=train_0, random_state=seed_value)\n",
    "test_df_0 = tweets_df_0[-test_0:]\n",
    "train_df_1 = tweets_df_1[:-test_1]\n",
    "train_df_1 = train_df_1.sample(n=train_1, random_state=seed_value)\n",
    "test_df_1 = tweets_df_1[-test_1:]\n",
    "\n",
    "train_df = pd.concat([train_df_0, train_df_1], ignore_index=True)\n",
    "test_df = pd.concat([test_df_0, test_df_1], ignore_index=True)\n",
    "len_label_0, len_label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bff64294",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "ds = DatasetDict()\n",
    "ds['train'] = train_ds.shuffle(seed=42)\n",
    "ds['test'] = test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0368dd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    15952\n",
       "1     3988\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3371d601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    3988\n",
       "1     997\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ff445ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'RT @AndrewJBates46: .@PressSec: \"The organization that is stopping [the pause] is Hamas.\"\\n\\n\"Israel has asked for a list of these women whoÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¦',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabca3a2-6915-4b76-9cc7-1ea104d76dab",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2726df25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yehoshd\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dc111d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8741e4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4982c88fcd374deca9b757f16b8bb82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19940 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8e67249df24c949d968e8d4a3db2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f12c5af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73f93ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ecd1126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "\n",
    "   # Calculate precision, recall, and F1-score\n",
    "    precision_0 = precision_score(labels, preds, pos_label=0, average='binary')\n",
    "    recall_0 = recall_score(labels, preds, pos_label=0, average='binary')\n",
    "    precision_1 = precision_score(labels, preds, pos_label=1, average='binary')\n",
    "    recall_1 = recall_score(labels, preds, pos_label=1, average='binary')\n",
    "\n",
    "    f1 = f1_score(labels, preds, average='average')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_0': precision_0,\n",
    "        'recall_0': recall_0,\n",
    "        'precision_1': precision_1,\n",
    "        'recall_1': recall_1,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c78cfd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'NEGATIVE', 1: 'POSITIVE'}, {'NEGATIVE': 0, 'POSITIVE': 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "id2label,label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d3d6c80-06ff-4b0b-9da6-8ed9973991b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "686f7196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-large',\n",
    "    num_labels=2, id2label=id2label, label2id=label2id,\n",
    "\n",
    ")\n",
    "model.to(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7b99216-947b-494b-ac1e-8f8e7548b4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load a trained model\n",
    "trained_model = AutoModelForSequenceClassification.from_pretrained('yehoshuadiller/twitter_classification_newest',\n",
    "    num_labels=2, id2label=id2label, label2id=label2id,\n",
    "\n",
    ")\n",
    "trained_model.to(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f25c0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"twitter_classification\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75ed4997",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m----> 2\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m,\n\u001b[0;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m      4\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      5\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      6\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m      7\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[0;32m      8\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m      9\u001b[0m     \n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8d920e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mydiller\u001b[0m (\u001b[33mnomorenms\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\yehoshd\\NLP\\twitter_classification\\wandb\\run-20240220_114715-julfk13r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nomorenms/huggingface/runs/julfk13r' target=\"_blank\">virtuous-pig-6</a></strong> to <a href='https://wandb.ai/nomorenms/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nomorenms/huggingface' target=\"_blank\">https://wandb.ai/nomorenms/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nomorenms/huggingface/runs/julfk13r' target=\"_blank\">https://wandb.ai/nomorenms/huggingface/runs/julfk13r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\transformers\\trainer.py:1530\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1527\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1528\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[0;32m   1529\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[1;32m-> 1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1537\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\transformers\\trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1875\u001b[0m ):\n\u001b[0;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\transformers\\trainer.py:2772\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2772\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2775\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\transformers\\trainer.py:2795\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2794\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2795\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2796\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2797\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1564\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1564\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1576\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1578\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1012\u001b[0m )\n\u001b[1;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    598\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         output_attentions,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:286\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    278\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    285\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 286\u001b[0m     mixed_query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# and values come from an encoder; the attention mask needs to be\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;66;03m# such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944c8b1a-bc59-488c-9030-185854798f06",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "009b53c5-9547-4707-bce5-1c92858c47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "\n",
    "   # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'all_preds': preds,\n",
    "        'all_labels': labels,\n",
    "        'raw_preds': pred.predictions,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96f77d6c-bb88-421f-8503-e5c85ec4c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_args = TrainingArguments(\n",
    "    output_dir=\"twitter_classification_evaluation\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5dd9824-aa8b-49eb-aad4-e5fd623e8f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaler = Trainer(\n",
    "    model=trained_model,\n",
    "    args=evaluation_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79a14868-5c01-4427-8f0f-fe0073f2ab9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1247' max='1247' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1247/1247 01:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mydiller\u001b[0m (\u001b[33mnomorenms\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Z:\\BayWatch\\yehoshua\\dev\\NLP\\twitter_classification\\wandb\\run-20240328_135133-mwvefhmr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nomorenms/huggingface/runs/mwvefhmr' target=\"_blank\">jumping-moon-23</a></strong> to <a href='https://wandb.ai/nomorenms/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nomorenms/huggingface' target=\"_blank\">https://wandb.ai/nomorenms/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nomorenms/huggingface/runs/mwvefhmr' target=\"_blank\">https://wandb.ai/nomorenms/huggingface/runs/mwvefhmr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "eval_results = evaler.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e4be413b-8634-4416-890d-f6af3c640aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from evaluate import evaluator\n",
    "# task_evaluator = evaluator(\"text-classification\")\n",
    "# eval_results = task_evaluator.compute(\n",
    "#     model_or_pipeline=\"yehoshuadiller/twitter_classification\",\n",
    "#     data=tokenized_ds[\"test\"],\n",
    "#     metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
    "#     label_mapping={\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4a0d09e-0713-48ff-b959-4f275bbc633d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.27009040117263794,\n",
       " 'eval_accuracy': 0.9410230692076229,\n",
       " 'eval_precision': 0.9486965257614732,\n",
       " 'eval_recall': 0.9410230692076229,\n",
       " 'eval_f1': 0.9429360464570667,\n",
       " 'eval_all_preds': array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       " 'eval_all_labels': array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       " 'eval_raw_preds': array([[ 2.157515 , -2.5734894],\n",
       "        [ 3.122507 , -3.8479733],\n",
       "        [ 3.128811 , -3.8627172],\n",
       "        ...,\n",
       "        [-2.2154922,  2.509962 ],\n",
       "        [-2.2154903,  2.5099626],\n",
       "        [-2.215492 ,  2.509962 ]], dtype=float32),\n",
       " 'eval_runtime': 70.1547,\n",
       " 'eval_samples_per_second': 71.057,\n",
       " 'eval_steps_per_second': 17.775}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2797231f-f1a0-4f16-a746-3eccbe5b06eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3742,  246],\n",
       "       [  48,  949]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = eval_results['eval_all_preds']\n",
    "labels = eval_results['eval_all_labels']\n",
    "cm = confusion_matrix(labels, preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00a3a2fc-ba05-4d8a-bc7e-97007bd77474",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m      3\u001b[0m             fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfusion_matrix.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm, annot=True, \n",
    "            fmt='.1f', cmap='Blues')\n",
    "plt.savefig(\"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5ed4794e-2488-44a9-964f-682971db3422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm/np.sum(cm, axis=0), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0977c90f-05db-4186-acdc-146a1541b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "scores = eval_results['eval_raw_preds']\n",
    "scores = softmax(scores, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5379b81-d3e1-42e3-8e00-19858007d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(labels, scores[:,1])\n",
    "area_under_curve = auc(recalls, precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0031bc65-93fa-49d8-9230-c89a99ecb086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recalls, precisions, label='Precision-Recall curve (AUC = {:.2f})'.format(area_under_curve))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.savefig('pr_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d569ddcf-4b73-4c7d-b68a-f038ada540ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = np.diag(cm) \n",
    "precision_per_cls = true_pos / np.sum(cm, axis=0)\n",
    "recall_per_cls = true_pos / np.sum(cm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a05eb06d-bb7e-455a-aca8-214c6b6f33ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98733509, 0.79414226])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_per_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "656d3181-ee9d-4796-b57b-289860e7ec4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93831494, 0.95185557])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_per_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e3caa-da8f-4295-8496-f52cdd31caaa",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c0c8507-9f35-472d-a789-fd758dd64319",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = scores[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bb3d05b-3a1f-498a-a527-2ec13881da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['similarity_score'] = similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f8a61bd-3e69-4d59-9fca-825043026d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This month, the American people voted to prote...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For too long, women have been underrepresented...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @POTUS: The choices we make today will dete...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢m proud to be the most pro-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are more people in the U.S. workforce to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>Iran-backed Hamas terrorists have been holding...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>Unconscionable and heartbreaking. We pray for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>IÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢m relieved more hostages ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>I'm incredibly relieved to hear that Abigail M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>We are pleased to see additional hostages be r...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4985 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     This month, the American people voted to prote...      0   \n",
       "1     For too long, women have been underrepresented...      0   \n",
       "2     RT @POTUS: The choices we make today will dete...      0   \n",
       "3     IÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢m proud to be the most pro-...      0   \n",
       "4     There are more people in the U.S. workforce to...      0   \n",
       "...                                                 ...    ...   \n",
       "4980  Iran-backed Hamas terrorists have been holding...      1   \n",
       "4981  Unconscionable and heartbreaking. We pray for ...      1   \n",
       "4982  IÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢m relieved more hostages ha...      1   \n",
       "4983  I'm incredibly relieved to hear that Abigail M...      1   \n",
       "4984  We are pleased to see additional hostages be r...      1   \n",
       "\n",
       "      similarity_score  \n",
       "0             0.008741  \n",
       "1             0.000938  \n",
       "2             0.000919  \n",
       "3             0.003400  \n",
       "4             0.000890  \n",
       "...                ...  \n",
       "4980          0.991211  \n",
       "4981          0.991211  \n",
       "4982          0.991211  \n",
       "4983          0.991211  \n",
       "4984          0.991211  \n",
       "\n",
       "[4985 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de8e3d81-098f-40da-bfb2-9f24f15f1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df = new_twits.copy()\n",
    "# temp_df['label'] = pd.to_numeric(tweets_df['label'], errors='coerce')\n",
    "# # Convert conflict_sentiment values which are different than 0 to 1\n",
    "# temp_df['label'] = temp_df['label'].apply(lambda x: 0 if x == 0 else 1)\n",
    "# temp_df_0 = temp_df[temp_df[\"label\"] == 0]\n",
    "# temp_df_1 = temp_df[temp_df[\"label\"] == 1]\n",
    "# df_sorted = temp_df_0.sort_values(by='upload_date')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
